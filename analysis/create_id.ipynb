{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "subjective-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "silent-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filenames):    \n",
    "    df_old = pd.read_csv(filenames[0])\n",
    "    df_new = pd.read_csv(filenames[1])\n",
    "    \n",
    "    return df_old, df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "every-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ids(df_old, df_new):\n",
    "    df_old[\"tmp_id\"] = df_old[\"Recipient Name\"] +\\\n",
    "    \"_\" + df_old[\"Project Name\"]\n",
    "    \n",
    "    df_new[\"tmp_id\"] = df_new[\"Recipient Name\"] +\\\n",
    "    \"_\" + df_new[\"Project Name\"]\n",
    "    \n",
    "    return df_old, df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "domestic-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df_old_with_id, df_new_with_id):\n",
    "    df_old_vetted = df_old_with_id[~df_old_with_id[\"vet\"].isnull()]\n",
    "    df_old_vetted_short = df_old_vetted[[\"tmp_id\", 'law_enforcement', 'court', 'corrections', 'cj_related','vet', 'reporter']]\n",
    "    \n",
    "    # merge the new dataset with rows from the old one that we looked at.\n",
    "    df_merge = pd.merge(df_new, df_old_vetted_short, on=\"tmp_id\", how=\"left\")\n",
    "    \n",
    "    # there are 33 rows that did not merge. Will export and investigate more.\n",
    "    id_joined = pd.merge(df_new_with_id, df_old_vetted_short, on=\"tmp_id\")[\"tmp_id\"].to_list()\n",
    "    df_did_not_merge = df_old_vetted[~df_old_vetted[\"tmp_id\"].isin(id_joined)]\n",
    "    \n",
    "    return df_merge, df_did_not_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "alert-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(df_merge, df_did_not_merge, df_merge_path, df_did_not_merge_path):\n",
    "    df_merge.to_csv(df_merge_path, index=False)\n",
    "    df_did_not_merge.to_csv(df_did_not_merge_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-helena",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fitted-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"source_data/cj_related/cj_related_old.csv\", \"source_data/cj_related/cj_related_new.csv\"]\n",
    "\n",
    "# read in two datasets\n",
    "df_old, df_new = read_data(filenames)\n",
    "# get unique id by combining columns in the two datasets\n",
    "df_old_with_id, df_new_with_id = get_unique_ids(df_old, df_new)\n",
    "# let's do some merging!\n",
    "df_merge, df_did_not_merge = merge(df_old_with_id, df_new_with_id)\n",
    "\n",
    "# export\n",
    "df_merge_path = \"output_data/q1_data_with_303_vetted_info.csv\"\n",
    "df_did_not_merge_path = \"output_data/missing_from_q1.csv\"\n",
    "export(df_merge, df_did_not_merge, df_merge_path, df_did_not_merge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-casting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
